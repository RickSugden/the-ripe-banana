+++
authors = []
date = 2020-09-06T04:00:00Z
draft = true
excerpt = ""
hero = "/images/the_thinker.jpg"
timeToRead = 8
title = "Thinking Fast and Slow"

+++
For my first real book selection, I have chosen a book that I think is a new fundamental part of my thinking that will come up again and again in future analyses: Daniel Kahneman's "Thinking Fast and Slow". In this post I will discuss some of the ideas I found most interesting and how I plan on applying them to my life. If you have not read it, I recommend every thinking person skim section one and carefully read the remaining four sections. For a brief sales pitch, see my goodreads review: [https://www.goodreads.com/review/show/3422865381](https://www.goodreads.com/review/show/3422865381 "Goodreads_thinking_fast_and_slow")

**Notes**

**Part 1:** 

* This part distinguishes Systems 1 and 2. 
* **System 1** is the fast, automatic, intuitive thinking that determines a picture of a screaming woman is angry. 
* **System 2** is the slow, deliberate, “logical” (has reasons) thinking that performs calculations or any other conscious thinking.

**Part 2:**

* Consider a study of kidney cancer reveals its incidence is lowest in rural, sparsely populated areas. We naturally associate these as causes for the low rates. In reality, longer studies showed that the cause of this finding was simply that being in a sparsely populated area made it easier for sample variation to show a high or low amount. The interesting part is that the sparsely populated part probably did not immediately strike you as relevant. 
* It is believed that 40% of psychological studies have a negative result only because their sample size is too low and so they fail to achieve statistical significance. It is a major problem that researchers choose sample size by intuition instead of statistics.
* Anchoring is priming effect where someone is shown a number and presumes it to be reasonable, future negotiations and decision making now take that in account and tend to gravitate towards that. E.g. max 5 per customer, probably gets more people to buy 5 than otherwise would. Don’t let anyone’s predictions influence your thinking.
* **Availability bias:** things that come easily to mind are believed to be more likely. They mistake plausible for probable. Participants selected an earthquake causing an American tsunami to be greater odds than just an American tsunami. 
* Availability cascade (halo effect): proness to thinking something is all good or all bad leading to incorrect extrapolation off initial information.
* Don’t forget base rates, study participants read of a guy who would be a perfect candidate for a librarian. When guessing their profession, they failed to take into account that few males are librarians.
* Dont assume people will learn from stats, give them representative cases to help them understand.
* In a series of events, unlikely results are likely followed by one that will **revert to the mean**. A random number 0 to 100, 6 is achieved, next one is likely to be closer to mean 50). So punishing a poor performance doesn’t necessarily work, it just statistically will revert to the mean anyway.

Part 3: narrative fallacy is that things seem predictable retrospectively and decisions are often evaluated based on their outcomes when really the conditions it was made in are the only relevant thing. Bad decisions can work out well - outcome bias.

When people can construct a cohesive narrative they feel good about it and think that their model of the world explains everything. Really it is much less predictable than that.

Replacing human judgement with a formula is almost always a good idea. Decide in advance what weight to give each factor in a decision.

You can only trust experts when they operate in a sufficiently predictable environment and when they are able to receive clear feedback quickly.

People are delusionally confident in their businesses because they can picture how it would succeed but its hard to picture how it fails. They also tend to neglect their competition.

Optimism is good for you in many ways but not in realistically assessing your performance or probability.

Clinicians who were “absolutely certain” of a diagnosis were wrong 40% of the time. Experts who admit their uncertainty are more likely to lose business to competitors.

Kahneman proposes a pre-mortem session strategy to prepare yourself for failure of a business instead of being blinded. Read engine of capitalism chapter for more details.

Part 4: expected utility value is not how people make decisions. There is non-linear relation where winning 1M for sure probably provides most of the value compared at a chance for 4M. You also need to consider circumstances such as two people with 6M, one doubled from 3 and one halved from 12, these people are not equally happy.

When dealing with gains people like the for sure option (risk averse) and when dealing with losses they prefer the gamble (risk taking). It appears that losses register psychologically as twice the weight of an equal gain.

The endowment effect states that people prefer things they already have. They randomly gave people a chocolate bar or a mug but majority did not want to trade for the other option.

People putt harder to avoid a bogey than achieve a birdie.

People perceive businesses as justified when raising prices because they have to but not because the market increased demand.

People overweight low probability events and so they become risk seeking when its a gain, potentially rejecting a favourable settlement and risk averse when the cost is high accepting an unfavourable settlement.

People are willing to pay a premium for certainty.

People prefer gains they can visualize and they prefer things where there are more chances to win even if the probability is lower (1 in 10 is not preferred vs 8 in 100)

A risk policy that flips and flops between sure gains and risk taking to avoid loss can actually result in the lowest expected outcome. You should pick a policy and stick with it. If offered a cointoss of win 150 lose 100, if you always accept, then over the course of your life it will bring expected value. Either always or never buy the extended warranty.

People avoid closing a “mental account” which results in a loss. They don’t want to end their shift until they made a days earnings. People keep separate accounts for different money when it’s all the same stuff. People are willing to pay x amount for safer but require much more of a discount than x to remove the safety bcs its taboo to trade safety for money.

Cab drivers make more on rainy days so they clock out earlier and stay longer on sunny days when you’d make more money doing the opposite.

Framing makes a difference such as 10% mortality vs 90% survival.